# Eigen.AI Knowledge Distillation Python Library
This repository provides an end-to-end implementation of Knowledge Distillation (KD) techniques (offline, online, self) for model compression and optimization. Check out .md for current goals of this prject.
- [ ] Offline Distillation Pipeline 
- [ ] Online Distillation Pipeline
- [ ] Self Distillation Pipeline 

## Features 

## Installation
To install the library, you can clone this repository and install the dependencies using pip:
```bash
git clone https://github.com/0xd1rac/eigen-distill-lib.git
cd eigen-distill-lib
pip install -r requirements.txt
```

## Usage 
### 1. Offline Disillation: Soft Output Strategy 
```python

```
